{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/iws/joliez/miniconda3/envs/cse481m-env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import all packages\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import gc\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EDIT VARIABLES HERE\n",
    "# pretrained_model_name_or_path = '/tmp/gte-Qwen1.5-7B-instruct' # on the other gpu\n",
    "pretrained_model_name_or_path = '/storage/huggingface_model/gte-Qwen1.5-7B-instruct' # on bonita\n",
    "# \"CohereLabs/aya-101\"\n",
    "# method may be model / data specific\n",
    "\n",
    "dataset = \"multitude\"\n",
    "if dataset == \"original\":\n",
    "    save_embed_dir = 'save/embeddings/'\n",
    "    save_kl_dir = 'save/kl_divergence/all_tokens/' \n",
    "    train_name = 'HC3_en_train'\n",
    "    val_name = 'HC3_en_valid'\n",
    "    train_path = 'dataset/processed_data/train_valid_data/HC3_en_train.json'\n",
    "    val_path = 'dataset/processed_data/train_valid_data/HC3_en_valid.json'\n",
    "    dataset_names = ['pub', 'writing', 'xsum']\n",
    "    labels_folder = 'labels/'\n",
    "elif dataset == \"counseling\":\n",
    "    save_embed_dir = 'save/counseling_embeddings/'\n",
    "    save_kl_dir = 'save/counseling_kl_divergence/all_tokens/' \n",
    "    train_name = 'train'\n",
    "    val_name = 'val'\n",
    "    train_path = 'dataset/processed_counseling/train.json'\n",
    "    val_path = 'dataset/processed_counseling/val.json'\n",
    "    test_path = 'dataset/processed_counseling/test.json'\n",
    "    labels_folder = 'dataset/processed_counseling/'\n",
    "    dataset_names = ['counseling']\n",
    "elif dataset == \"multitude\":\n",
    "    save_embed_dir = 'save/multitude_embeddings/'\n",
    "    save_kl_dir = 'save/multitude_kl_divergence/all_tokens/' \n",
    "    train_name = 'es_train'\n",
    "    val_name = 'es_val'\n",
    "    train_path = 'dataset/processed_multitude/train_valid_data/es_train.json'\n",
    "    val_path = 'dataset/processed_multitude/train_valid_data/es_val.json'\n",
    "    test_path = 'dataset/processed_multitude/test_data/es_test.json'\n",
    "    labels_folder = 'dataset/processed_multitude/labels/'\n",
    "    test_dir = 'dataset/processed_multitude/test_data'\n",
    "    dataset_names = ['en']\n",
    "    # dataset_names = ['ar', 'ca', 'cs', 'de', 'en', 'es', 'nl', 'pt', 'ru', 'uk', 'zh']\n",
    "\n",
    "os.makedirs(save_embed_dir, exist_ok=True)  \n",
    "os.makedirs(save_kl_dir, exist_ok=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:03<00:00,  2.01it/s]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 1, 'model.layers.5': 1, 'model.layers.6': 1, 'model.layers.7': 1, 'model.layers.8': 1, 'model.layers.9': 1, 'model.layers.10': 1, 'model.layers.11': 1, 'model.layers.12': 1, 'model.layers.13': 1, 'model.layers.14': 2, 'model.layers.15': 2, 'model.layers.16': 2, 'model.layers.17': 2, 'model.layers.18': 2, 'model.layers.19': 2, 'model.layers.20': 2, 'model.layers.21': 2, 'model.layers.22': 2, 'model.layers.23': 2, 'model.layers.24': 3, 'model.layers.25': 3, 'model.layers.26': 3, 'model.layers.27': 3, 'model.layers.28': 3, 'model.layers.29': 3, 'model.layers.30': 3, 'model.layers.31': 3, 'model.norm': 3, 'lm_head': 'cpu'}\n"
     ]
    }
   ],
   "source": [
    "# global variables\n",
    "embedding_dim = 4096\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# load model\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path, trust_remote_code=True, local_files_only=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path, trust_remote_code=True,device_map='auto', local_files_only=True)\n",
    "print(model.hf_device_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(path, file_name, save_kl):\n",
    "    \n",
    "    def last_token_pool(last_hidden_states, attention_mask):\n",
    "        left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])\n",
    "        if left_padding:\n",
    "            return last_hidden_states[:, -1]\n",
    "        else:\n",
    "            sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "            batch_size = last_hidden_states.shape[0]\n",
    "            return last_hidden_states[torch.arange(batch_size, device='cpu'), sequence_lengths]\n",
    "    \n",
    "    \n",
    "    def get_kl_and_embeddings(input_texts, save_kl):\n",
    "        print('get_kl_and_embeddings being called')\n",
    "        num_tokens = tokenizer(input_texts, return_tensors='pt', truncation=False, padding=False)['input_ids'].shape[1]\n",
    "        # print(num_tokens)\n",
    "        max_length = 300\n",
    "        batch_dict = tokenizer(input_texts, max_length=max_length, padding=True, truncation=True, return_tensors='pt')\n",
    "        # print(batch_dict['input_ids'].shape)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch_dict,output_hidden_states=True)\n",
    "            # print(\"pass here\")\n",
    "            if save_kl: \n",
    "                # todo: used for test\n",
    "                last_logits = model.lm_head(outputs.hidden_states[-1]).squeeze()\n",
    "                first_logits = model.lm_head(outputs.hidden_states[0]).squeeze()\n",
    "                \n",
    "        \n",
    "        all_embed = [last_token_pool(outputs.hidden_states[i].cpu(), batch_dict['attention_mask']) for i in range(len(outputs.hidden_states))]\n",
    "        all_embed_concated = torch.concat(all_embed,1).cpu()\n",
    "\n",
    "        if save_kl: \n",
    "            # # todo: used for test\n",
    "            # last_logits = all_embed[-1]\n",
    "            # # first_logits = all_embed[0]\n",
    "            # first_logits = all_embed[1]\n",
    "        \n",
    "            kls = []\n",
    "            for i in range(1,len(outputs.hidden_states)-1):\n",
    "                with torch.no_grad():\n",
    "                    middle_logits = model.lm_head(outputs.hidden_states[i]).squeeze()\n",
    "                    # todo: used for test\n",
    "                    # middle_logits = all_embed[i]\n",
    "                kls.append(F.kl_div(F.log_softmax(middle_logits, dim=-1), F.softmax(first_logits, dim=-1), reduction='batchmean').item()+\n",
    "                        F.kl_div(F.log_softmax(middle_logits, dim=-1), F.softmax(last_logits, dim=-1), reduction='batchmean').item())\n",
    "            return kls, all_embed_concated\n",
    "        \n",
    "        return all_embed_concated\n",
    "\n",
    "\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    if file_name == 'HC3_en_train':\n",
    "        data = data[:200]\n",
    "    elif file_name == 'HC3_en_valid':\n",
    "        data = data[:40]\n",
    "\n",
    "    kls = []\n",
    "    embeddings = []\n",
    "    for text_info in tqdm(data):\n",
    "        text = text_info['text']\n",
    "        result = text_info['result']\n",
    "        prompt = text\n",
    "        if save_kl: \n",
    "            kl, embedding = get_kl_and_embeddings([text], True)\n",
    "            if kl is not None :\n",
    "                kls.append(kl)\n",
    "                embeddings.append(embedding)\n",
    "        else :\n",
    "            embedding = get_kl_and_embeddings([text], False)\n",
    "            embeddings.append(embedding)\n",
    "            if kl is not None :\n",
    "                kls.append(kl)\n",
    "\n",
    "\n",
    "    # save kl divergence\n",
    "    if save_kl:\n",
    "        print(save_kl_dir+file_name+'.pkl')\n",
    "        pickle.dump(kls, open(save_kl_dir+file_name+'.pkl', 'wb'))\n",
    "\n",
    "    # save embeddings\n",
    "    embeddings = torch.cat(embeddings, dim=0)\n",
    "    print(save_embed_dir+file_name+'.pt')\n",
    "    torch.save(embeddings, save_embed_dir+file_name+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_and_labels(file_name, data_path, device, layer_num):\n",
    "    print(\"trying to get\", file_name)\n",
    "    # print(data_path)\n",
    "    labels = torch.load(labels_folder + file_name + '.pt').to(device)\n",
    "    try:\n",
    "        embeddings = torch.load(save_embed_dir + file_name + '.pt')             \n",
    "    except FileNotFoundError:\n",
    "        # If saved embeddings not found, generate them\n",
    "        print('target file not found, start generating embeddings')\n",
    "        # print(data_path)\n",
    "        generate_embeddings(data_path, file_name, layer_num == -1) #only compute and save kl is layer_num==-1, which means max-kl\n",
    "        embeddings = torch.load(save_embed_dir + file_name + '.pt') \n",
    "    \n",
    "    if layer_num != -1:\n",
    "        embeddings = embeddings[:,embedding_dim * layer_num: embedding_dim * (layer_num + 1)].to(device)\n",
    "    else: #max_kl\n",
    "        # with open(f'save/kl_divergence/last_token/' + file_name + '.pkl', 'rb') as f:\n",
    "        with open(save_kl_dir + file_name + '.pkl', 'rb') as f:\n",
    "            kl = pickle.load(f)\n",
    "            kl = np.array(kl)\n",
    "            idx = kl.argmax(axis=1)\n",
    "            embeddings = torch.tensor([row[(i+1)*embedding_dim:(i+2)*embedding_dim].tolist() for row ,i in zip(embeddings,idx) ]).to(device)\n",
    "\n",
    "    return embeddings, labels\n",
    "    \n",
    "\n",
    "def get_train_eval_data(layer_num, device, train_num = 160, valid_num = 20) :\n",
    "    train_embeddings, train_labels = get_embeddings_and_labels(train_name, train_path, device, layer_num)\n",
    "    valid_embeddings, valid_labels = get_embeddings_and_labels(val_name, val_path, device, layer_num)\n",
    "    return train_embeddings[:train_num], train_labels[:train_num], valid_embeddings[:valid_num], valid_labels[:valid_num]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't edit this cell\n",
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes=[1024, 512], num_labels=2, dropout_prob=0.2):\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.extend([\n",
    "                nn.Dropout(dropout_prob),\n",
    "                nn.Linear(prev_size, hidden_size),\n",
    "                nn.Tanh(),\n",
    "            ])\n",
    "            prev_size = hidden_size\n",
    "        self.dense = nn.Sequential(*layers)\n",
    "        self.classifier = nn.Linear(prev_size, num_labels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.dense(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(layer_num, device, hidden_sizes = [1024,512], droprate = 0.4, num_epochs = 10, learning_rate = 0.003):\n",
    "    train_embeddings, train_labels, valid_embeddings, valid_labels = get_train_eval_data(layer_num, device)\n",
    "    # print(train_embeddings.mean())\n",
    "    print(\"the device being used is\", device)\n",
    "    print(\"there are\", train_embeddings.shape[0], \"train data and\", valid_embeddings.shape[0], \"validation data.\")\n",
    "    input_size = train_embeddings.shape[1]\n",
    "    \n",
    "    model = BinaryClassifier(input_size,hidden_sizes=hidden_sizes,dropout_prob=droprate).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    batch_size = 16\n",
    "    best_valid_acc = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(0, len(train_embeddings), batch_size):\n",
    "            model.train()\n",
    "            batch_embeddings = train_embeddings[i:i+batch_size].to(device)\n",
    "            batch_labels = train_labels[i:i+batch_size].to(device)\n",
    "            outputs = model(batch_embeddings)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(valid_embeddings)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            accuracy = (predicted == valid_labels).sum().item() / len(valid_labels)\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Validation Accuracy: {accuracy:.4f}\")\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(device, dataset_names, layer_num) :\n",
    "    testset_embeddings, testset_labels, data_and_model_names = [], [], []\n",
    "    for dataset_name in dataset_names: \n",
    "        if dataset == 'original':\n",
    "            for model_name in ['gpt3.5', 'gpt4', 'claude3']:\n",
    "                test_embeddings, test_labels = get_embeddings_and_labels(dataset_name + '_' + model_name, \n",
    "                    'processed_data/test_data/' + dataset_name + '_' + model_name + '.json', device, layer_num)\n",
    "                testset_embeddings.append(test_embeddings)\n",
    "                testset_labels.append(test_labels)\n",
    "                data_and_model_names.append(dataset_name + \"-\" + model_name)\n",
    "        elif dataset == 'multitude':\n",
    "            for model_name in ['gpt-3.5-turbo', 'gpt-4']:\n",
    "                test_embeddings, test_labels = get_embeddings_and_labels(\n",
    "                    f'{dataset_name}_{model_name}', \n",
    "                    f'{test_dir}/{dataset_name}_{model_name}.json', device, layer_num)\n",
    "                testset_embeddings.append(test_embeddings)\n",
    "                testset_labels.append(test_labels)\n",
    "                data_and_model_names.append(dataset_name + \"-\" + model_name)\n",
    "        else: \n",
    "            test_embeddings, test_labels = get_embeddings_and_labels('test', test_path, device, layer_num)\n",
    "            testset_embeddings.append(test_embeddings)\n",
    "            testset_labels.append(test_labels)\n",
    "            data_and_model_names.append(dataset_name)\n",
    "\n",
    "    return testset_embeddings, testset_labels, data_and_model_names\n",
    "\n",
    "def group_and_average(name_to_auroc):\n",
    "    grouped = defaultdict(list)\n",
    "    for name, auroc in name_to_auroc.items():\n",
    "        name_lower = name.lower()\n",
    "        if 'gpt3' in name_lower or 'chatgpt' in name_lower:\n",
    "            grouped['gpt3.5'].append(auroc)\n",
    "        elif 'gpt4' in name_lower:\n",
    "            grouped['gpt4'].append(auroc)\n",
    "        elif 'claude' in name_lower:\n",
    "            grouped['claude3'].append(auroc)\n",
    "        elif 'gpt-3.5-turbo' in name_lower:\n",
    "            grouped['gpt-3.5-turbo'].append(auroc)\n",
    "        elif 'gpt-4' in name_lower:\n",
    "            grouped['gpt-4'].append(auroc)\n",
    "        elif dataset == 'counseling':\n",
    "            grouped['counseling'].append(auroc)\n",
    "        else:\n",
    "            print(f\"Warning: could not classify {name}\")\n",
    "    \n",
    "    avg_aurocs = {}\n",
    "    for model_type in ['gpt3.5', 'gpt4', 'claude3', '', 'counseling', 'gpt-3.5-turbo', 'gpt-4']:\n",
    "        if grouped[model_type]:\n",
    "            avg_aurocs[model_type] = sum(grouped[model_type]) / len(grouped[model_type])\n",
    "        else:\n",
    "            avg_aurocs[model_type] = None\n",
    "    \n",
    "    return avg_aurocs\n",
    "\n",
    "\n",
    "def run_single_test(model,test_set,test_label,test_acc,testset_name):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(test_set)\n",
    "        probabilities = torch.softmax(outputs, dim=1)[:, 1]\n",
    "        auroc = roc_auc_score(test_label.cpu().numpy(), probabilities.cpu().numpy())\n",
    "        test_acc.append(auroc)\n",
    "    return auroc\n",
    "\n",
    "def run_all_tests(model, layer_num, device, dataset_names) :\n",
    "    testset_embeddings, testset_labels, data_and_model_names = get_test_data(device, dataset_names, layer_num)\n",
    "    with torch.no_grad():\n",
    "        name_to_auroc = {}\n",
    "        for test_embed, test_label, data_and_model_name in zip(testset_embeddings, testset_labels, data_and_model_names):\n",
    "            auroc = run_single_test(model, test_embed, test_label, [], ' ')\n",
    "            name_to_auroc[data_and_model_name] = auroc\n",
    "    return name_to_auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_one_layer(layer_num, device, dataset_names):\n",
    "    model = train(layer_num, device)\n",
    "    name_to_auroc = run_all_tests(model, layer_num, device, dataset_names)\n",
    "    # print(name_to_auroc)\n",
    "    # avg_aurocs = group_and_average(name_to_auroc)\n",
    "    return name_to_auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_and_test_one_layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_and_test_one_layer\u001b[49m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, device, dataset_names)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_and_test_one_layer' is not defined"
     ]
    }
   ],
   "source": [
    "train_and_test_one_layer(-1, device, dataset_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first layer\n",
    "avg_aurocs = train_and_test_one_layer(0, device, dataset_names)\n",
    "print(avg_aurocs)\n",
    "\n",
    "# last layer\n",
    "avg_aurocs = train_and_test_one_layer(32, device, dataset_names)\n",
    "print(avg_aurocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_to_aurocs = {'gpt3.5': [], 'gpt4': [], 'claude3': []}\n",
    "# layer_nums = []\n",
    "\n",
    "# for layer_num in range(33):\n",
    "#     print(\"layer_num =\", layer_num)\n",
    "#     layer_nums.append(layer_num)\n",
    "#     avg_aurocs = train_and_test_one_layer(layer_num, device)\n",
    "#     for model_type in ['gpt3.5', 'gpt4', 'claude3']:\n",
    "#         layer_to_aurocs[model_type].append(avg_aurocs[model_type])\n",
    "\n",
    "\n",
    "# # plot (similar to Figure 2 in their paper)\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# for model_type, aucs in layer_to_aurocs.items():\n",
    "#     plt.plot(layer_nums, aucs, label=model_type)\n",
    "\n",
    "# plt.xlabel('Layer Number')\n",
    "# plt.ylabel('Average AUROC')\n",
    "# plt.title('Layer vs AUROC for Different Models')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # first layer\n",
    "# avg_aurocs = train_and_test_one_layer(0, device)\n",
    "# print(avg_aurocs)\n",
    "\n",
    "# last layer\n",
    "avg_aurocs = train_and_test_one_layer(22, device, ['pub'])\n",
    "print(avg_aurocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse481m-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
